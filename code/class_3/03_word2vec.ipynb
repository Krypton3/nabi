{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec 모델을 간단하게 구현해봅니다.\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplot 에서 한글을 표시하기 위한 설정\n",
    "font_name = matplotlib.font_manager.FontProperties(\n",
    "                fname=\"c:/Windows/Fonts/malgun.ttf\"  # 한글 폰트 위치를 넣어주세요\n",
    "            ).get_name()\n",
    "matplotlib.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 벡터를 분석해볼 임의의 문장들\n",
    "sentences = [\"나 고양이 좋다\",\n",
    "             \"나 강아지 좋다\",\n",
    "             \"나 동물 좋다\",\n",
    "             \"강아지 고양이 동물\",\n",
    "             \"여자친구 고양이 강아지 좋다\",\n",
    "             \"고양이 생선 우유 좋다\",\n",
    "             \"강아지 생선 싫다 우유 좋다\",\n",
    "             \"강아지 고양이 눈 좋다\",\n",
    "             \"나 여자친구 좋다\",\n",
    "             \"여자친구 나 싫다\",\n",
    "             \"여자친구 나 영화 책 음악 좋다\",\n",
    "             \"나 게임 만화 애니 좋다\",\n",
    "             \"고양이 강아지 싫다\",\n",
    "             \"강아지 고양이 좋다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 전부 합친 후 공백으로 단어들을 나누고 고유한 단어들로 리스트를 만듭니다.\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "# 문자열로 분석하는 것 보다, 숫자로 분석하는 것이 훨씬 용이하므로\n",
    "# 리스트에서 문자들의 인덱스를 뽑아서 사용하기 위해,\n",
    "# 이를 표현하기 위한 연관 배열과, 단어 리스트에서 단어를 참조 할 수 있는 인덱스 배열을 만듭합니다.\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "word_index = [word_dict[word] for word in word_list]\n",
    "\n",
    "# 윈도우 사이즈를 1 로 하는 skip-gram 모델을 만듭니다.\n",
    "# 예) 나 게임 만화 애니 좋다\n",
    "#   -> ([나, 만화], 게임), ([게임, 애니], 만화), ([만화, 좋다], 애니)\n",
    "#   -> (게임, 나), (게임, 만화), (만화, 게임), (만화, 애니), (애니, 만화), (애니, 좋다)\n",
    "skip_grams = []\n",
    "\n",
    "for i in range(1, len(word_index) - 1):\n",
    "    # (context, target) : ([target index - 1, target index + 1], target)\n",
    "    target = word_index[i]\n",
    "    context = [word_index[i - 1], word_index[i + 1]]\n",
    "\n",
    "    # (target, context[0]), (target, context[1])..\n",
    "    for w in context:\n",
    "        skip_grams.append([target, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip-gram 데이터에서 무작위로 데이터를 뽑아 입력값과 출력값의 배치 데이터를 생성하는 함수\n",
    "def random_batch(data, size):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
    "\n",
    "    for i in random_index:\n",
    "        random_inputs.append(data[i][0])  # target\n",
    "        random_labels.append([data[i][1]])  # context word\n",
    "\n",
    "    return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "# 학습을 반복할 횟수\n",
    "training_epoch = 300\n",
    "# 학습률\n",
    "learning_rate = 0.1\n",
    "# 한 번에 학습할 데이터의 크기\n",
    "batch_size = 20\n",
    "# 단어 벡터를 구성할 임베딩 차원의 크기\n",
    "# 이 예제에서는 x, y 그래프로 표현하기 쉽게 2 개의 값만 출력하도록 합니다.\n",
    "embedding_size = 2\n",
    "# word2vec 모델을 학습시키기 위한 nce_loss 함수에서 사용하기 위한 샘플링 크기\n",
    "# batch_size 보다 작아야 합니다.\n",
    "num_sampled = 15\n",
    "# 총 단어 갯수\n",
    "voc_size = len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "# tf.nn.nce_loss 를 사용하려면 출력값을 이렇게 [batch_size, 1] 구성해야합니다.\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "# word2vec 모델의 결과 값인 임베딩 벡터를 저장할 변수입니다.\n",
    "# 총 단어 갯수와 임베딩 갯수를 크기로 하는 두 개의 차원을 갖습니다.\n",
    "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "# 임베딩 벡터의 차원에서 학습할 입력값에 대한 행들을 뽑아옵니다.\n",
    "# 예) embeddings     inputs    selected\n",
    "#    [[1, 2, 3]  -> [2, 3] -> [[2, 3, 4]\n",
    "#     [2, 3, 4]                [3, 4, 5]]\n",
    "#     [3, 4, 5]\n",
    "#     [4, 5, 6]]\n",
    "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "\n",
    "# nce_loss 함수에서 사용할 변수들을 정의합니다.\n",
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "# nce_loss 함수를 직접 구현하려면 매우 복잡하지만,\n",
    "# 함수를 텐서플로우가 제공하므로 그냥 tf.nn.nce_loss 함수를 사용하기만 하면 됩니다.\n",
    "loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size))\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step  10 :  4.63294\n",
      "loss at step  20 :  4.1159\n",
      "loss at step  30 :  3.61612\n",
      "loss at step  40 :  3.6589\n",
      "loss at step  50 :  3.30942\n",
      "loss at step  60 :  3.24721\n",
      "loss at step  70 :  3.0869\n",
      "loss at step  80 :  3.17798\n",
      "loss at step  90 :  3.09106\n",
      "loss at step  100 :  3.02595\n",
      "loss at step  110 :  2.93165\n",
      "loss at step  120 :  2.79173\n",
      "loss at step  130 :  2.86458\n",
      "loss at step  140 :  2.79163\n",
      "loss at step  150 :  2.79434\n",
      "loss at step  160 :  2.7695\n",
      "loss at step  170 :  2.72192\n",
      "loss at step  180 :  2.69603\n",
      "loss at step  190 :  2.64792\n",
      "loss at step  200 :  2.68526\n",
      "loss at step  210 :  2.62035\n",
      "loss at step  220 :  2.66425\n",
      "loss at step  230 :  2.55111\n",
      "loss at step  240 :  2.61309\n",
      "loss at step  250 :  2.53047\n",
      "loss at step  260 :  2.53817\n",
      "loss at step  270 :  2.4365\n",
      "loss at step  280 :  2.44365\n",
      "loss at step  290 :  2.59589\n",
      "loss at step  300 :  2.48038\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_epoch + 1):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                               feed_dict={inputs: batch_inputs,\n",
    "                                          labels: batch_labels})\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss at step \", step, \": \", loss_val)\n",
    "\n",
    "    # matplot 으로 출력하여 시각적으로 확인해보기 위해\n",
    "    # 임베딩 벡터의 결과 값을 계산하여 저장합니다.\n",
    "    # with 구문 안에서는 sess.run 대신 간단히 eval() 함수를 사용할 수 있습니다.\n",
    "    trained_embeddings = embeddings.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chuckgu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\font_manager.py:1316: UserWarning: findfont: Font family ['NanumGothicOTF'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBOb/AbtdxTQouMWpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20cda21b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########\n",
    "# 임베딩된 Word2Vec 결과 확인\n",
    "# 결과는 해당 단어들이 얼마나 다른 단어와 인접해 있는지를 보여줍니다.\n",
    "######\n",
    "for i, label in enumerate(word_list):\n",
    "    x, y = trained_embeddings[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
